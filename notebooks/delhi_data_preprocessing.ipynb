{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from shutil import copy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# from albk.data.utils import idx_to_locate\n",
    "use_disjoint_files = False\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# from astra.torch.models import EfficientNetClassifier,EfficientNet_B0_Weights\n",
    "# from astra.torch.utils import train_fn\n",
    "\n",
    "import torchvision.models as models\n",
    "# from astra.torch.metrics import accuracy_score, f1_score, precision_score, recall_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_label_files(path1, path2):\n",
    "    files1 = glob(join(path1, \"*.nc\"))\n",
    "    files2 = glob(join(path2, \"*.nc\"))\n",
    "    \n",
    "    f1_base_files = [basename(f) for f in files1]\n",
    "    f2_base_files = [basename(f) for f in files2]\n",
    "    \n",
    "    common_files = set(f1_base_files).intersection(f2_base_files)\n",
    "    common_label_files = []\n",
    "    for file in common_files:\n",
    "        ds1 = xr.open_dataset(join(path1, file))\n",
    "        ds2 = xr.open_dataset(join(path2, file))\n",
    "        if np.all(ds1.label.values == ds2.label.values):\n",
    "            common_label_files.append(file)\n",
    "    \n",
    "    return list(map(lambda f: join(path1, f), common_label_files))\n",
    "\n",
    "def get_disjoint_files(path1, path2):\n",
    "    files1 = glob(join(path1, \"*.nc\"))\n",
    "    files2 = glob(join(path2, \"*.nc\"))\n",
    "    \n",
    "    f1_base_files = [basename(f) for f in files1]\n",
    "    f2_base_files = [basename(f) for f in files2]\n",
    "    \n",
    "    disjoint_files = set(f1_base_files).symmetric_difference(f2_base_files)\n",
    "    \n",
    "    f1_disjoint = [f for f in disjoint_files if f in f1_base_files]\n",
    "    f1_disjoint = list(map(lambda f: join(path1, f), f1_disjoint))\n",
    "\n",
    "    f2_disjoint = [f for f in disjoint_files if f in f2_base_files]\n",
    "    f2_disjoint = list(map(lambda f: join(path2, f), f2_disjoint))\n",
    "    \n",
    "    return f1_disjoint + f2_disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderator rishabh\n",
      "      Moderator files 151\n",
      "      Common label files 98\n",
      "      Disjoint files 0\n",
      "      Total files from rishabh and ('shataxi', 'suraj') 249\n",
      "      Total annotatated files 249\n",
      "Moderator suraj\n",
      "      Moderator files 88\n",
      "      Common label files 64\n",
      "      Disjoint files 0\n",
      "      Total files from suraj and ('rishabh', 'vannsh') 152\n",
      "      Total annotatated files 401\n",
      "Total dataset size 10025\n"
     ]
    }
   ],
   "source": [
    "base_path = expanduser(\"/home/rishabh.mondal/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data\")\n",
    "paths = {\"rishabh\": (\"shataxi\", \"suraj\"), \"suraj\": (\"rishabh\", \"vannsh\")}\n",
    "\n",
    "all_labeled_files = []\n",
    "for moderator, annotators in paths.items():\n",
    "    # Get moderator files\n",
    "    moderator_path = join(base_path, \"moderated\", moderator)\n",
    "    moderator_files = glob(join(moderator_path, \"*.nc\"))\n",
    "    \n",
    "    # Get annotator common label files\n",
    "    annotator1_path = join(base_path, annotators[0])\n",
    "    annotator2_path = join(base_path, annotators[1])\n",
    "    \n",
    "    common_base_files = get_common_label_files(annotator1_path, annotator2_path)\n",
    "    \n",
    "    # Get disjoint files\n",
    "    disjoint_files = get_disjoint_files(annotator1_path, annotator2_path)\n",
    "    \n",
    "    all_files = moderator_files + common_base_files\n",
    "    if use_disjoint_files:\n",
    "        all_files.extend(disjoint_files)\n",
    "    assert len(all_files) == len(set(all_files))\n",
    "    all_labeled_files.extend(all_files)\n",
    "    \n",
    "    print(\"Moderator\", moderator)\n",
    "    print(\" \"*5, \"Moderator files\", len(moderator_files))\n",
    "    print(\" \"*5, \"Common label files\", len(common_base_files))\n",
    "    print(\" \"*5, \"Disjoint files\", len(disjoint_files))\n",
    "    print(\" \"*5, f\"Total files from {moderator} and {annotators}\", len(all_files))\n",
    "    print(\" \"*5, \"Total annotatated files\", len(all_labeled_files))\n",
    "    \n",
    "print(\"Total dataset size\", len(all_labeled_files) * 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labeled_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rishabh.mondal/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data/moderated/rishabh/28.90,77.25.nc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labeled_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a torch dataset from the files\n",
    "\n",
    "def process_file(file):\n",
    "    raw_file_path = f\"/home/rishabh.mondal/bkdb/statewise/sarath_data1/{file.split('/')[-1].rsplit('.', 1)[0]}.zarr\"\n",
    "    try:\n",
    "        ds = xr.open_zarr(raw_file_path, consolidated=False)\n",
    "    except:\n",
    "        print(f\"Failed to open {raw_file_path}\")\n",
    "        return\n",
    "    label_ds = xr.open_dataset(file)\n",
    "    image_label_pairs = []\n",
    "    for lat_lag in [-2, -1, 0, 1, 2]:\n",
    "        for lon_lag in [-2, -1, 0, 1, 2]:\n",
    "            img = Image.fromarray(ds.sel(lat_lag=lat_lag, lon_lag=lon_lag)['data'].values)\n",
    "            label = label_ds.sel(lat_lag=lat_lag, lon_lag=lon_lag)['label'].values.item()\n",
    "            # img.save(f\"/tmp/bk_new_delhi/{file.split('/')[-1].rsplit('.', 1)[0]}_{lat_lag}_{lon_lag}_{label}.png\")\n",
    "\n",
    "_ = Parallel(n_jobs=32)(delayed(process_file)(file) for file in tqdm(all_labeled_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
