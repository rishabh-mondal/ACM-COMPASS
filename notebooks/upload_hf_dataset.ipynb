{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from einops import rearrange, reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import huggingface_hub as hf_hub\n",
    "import datasets as ds\n",
    "from PIL import Image\n",
    "import torch\n",
    "import tarfile\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# import transforms\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40997\n"
     ]
    }
   ],
   "source": [
    "state = \"haryana\"\n",
    "files = sorted(glob(f\"/home/jaiswalsuraj/bkdb/india/{state}/*.zarr\"))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f22722b432485db4d95c68112b0dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jaiswalsuraj/bkdb/india/haryana/28.75,76.20.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/28.75,76.23.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/28.75,76.24.zarr lon not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/28.75,76.32.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/28.75,76.49.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/30.07,76.74.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/30.07,76.75.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/30.07,76.80.zarr lon not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/30.07,76.87.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/30.07,76.89.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/30.07,76.99.zarr lat not found\n",
      "/home/jaiswalsuraj/bkdb/india/haryana/30.07,77.00.zarr lat not found\n"
     ]
    }
   ],
   "source": [
    "os.system(f\"rm -rf /tmp/hfbk_{state}\")\n",
    "os.system(f\"mkdir /tmp/hfbk_{state}\")\n",
    "\n",
    "def process(file):\n",
    "    with xr.open_zarr(file, consolidated=False) as ds:\n",
    "        pass\n",
    "    try:\n",
    "        lat = ds['lat'].values.item()\n",
    "    except KeyError:\n",
    "        print(file, \"lat not found\")\n",
    "        return\n",
    "    try:\n",
    "        lon = ds['lon'].values.item()\n",
    "    except KeyError:\n",
    "        print(file, \"lon not found\")\n",
    "        return \n",
    "    lat_lon = f\"{lat}_{lon}\"\n",
    "    val = ds['data'].values\n",
    "    val = rearrange(val, 'rb cb r c ch -> (rb r) (cb c) ch')\n",
    "    # da = xr.DataArray(val, dims=['lat_lon', 'r', 'c', 'ch'], coords={'lat_lon': [lat_lon]})\n",
    "    # return da\n",
    "    img = Image.fromarray(val)\n",
    "    img.save(f\"/tmp/hfbk_{state}/{file.split('/')[-1].replace('.zarr', '.png')}\")\n",
    "\n",
    "# da_list = Parallel(n_jobs=48)(delayed(process)(file) for file in tqdm(files[:2048]))\n",
    "# ds = xr.concat(da_list, dim='lat_lon').to_dataset(name='data')\n",
    "# ds.to_zarr(f\"/tmp/hfbk_{state}/data.zarr.zip\", mode='w')\n",
    "_ = Parallel(n_jobs=48)(delayed(process)(file) for file in tqdm(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b15f1704934acc99110b42e8f5919e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/hfbk_haryana/data_000.tar\n",
      "Writing /tmp/hfbk_haryana/data_001.tar\n",
      "Writing /tmp/hfbk_haryana/data_002.tar\n",
      "Writing /tmp/hfbk_haryana/data_003.tar\n",
      "Writing /tmp/hfbk_haryana/data_004.tar\n",
      "Writing /tmp/hfbk_haryana/data_005.tar\n"
     ]
    }
   ],
   "source": [
    "# create a tar file each containing b_size images\n",
    "b_size = 4096*2\n",
    "files = sorted(glob(f\"/tmp/hfbk_{state}/*.png\"))\n",
    "print(len(files))\n",
    "\n",
    "for idx, i in tqdm(enumerate(range(0, len(files), b_size))):\n",
    "    name = f\"/tmp/hfbk_{state}/data_{str(idx).zfill(3)}.tar\"\n",
    "    print(\"Writing\", name)\n",
    "    with tarfile.open(name, \"w\") as tar:\n",
    "        for file in files[i:i+b_size]:\n",
    "            tar.add(file, arcname=file.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47477 entries, 0 to 47476\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   file    47477 non-null  object \n",
      " 1   lat     47477 non-null  float64\n",
      " 2   lon     47477 non-null  float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# save file names to metadata\n",
    "df = pd.DataFrame(map(lambda x: x.split(\"/\")[-1].rsplit(\".\", 1)[0], files), columns=['file'])\n",
    "df['lat'] = df['file'].apply(lambda x: float(x.split(',')[0]))\n",
    "df['lon'] = df['file'].apply(lambda x: float(x.split(',')[1]))\n",
    "df.to_csv(f\"/tmp/hfbk_{state}/metadata.csv\", index=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "from datasets.tasks import ImageClassification\n",
    "\n",
    "\n",
    "_DATA_URL = {\n",
    "    \"train\": [f\"data/data_{i}.tar\" for i in range(6)],\n",
    "}\n",
    "\n",
    "\n",
    "class Imagenet1k(datasets.GeneratorBasedBuilder):\n",
    "    VERSION = datasets.Version(\"1.0.0\")\n",
    "\n",
    "    def _info(self):\n",
    "        return datasets.DatasetInfo(\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"image\": datasets.Image(),\n",
    "                    \"name\": datasets.Value(\"string\"),\n",
    "                }\n",
    "            ),\n",
    "            # task_templates=[ImageClassification(image_column=\"image\", label_column=\"label\")],\n",
    "        )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        \"\"\"Returns SplitGenerators.\"\"\"\n",
    "        archives = dl_manager.download(_DATA_URL)\n",
    "\n",
    "        return [\n",
    "            datasets.SplitGenerator(\n",
    "                name=datasets.Split.TRAIN,\n",
    "                gen_kwargs={\n",
    "                    \"archives\": [dl_manager.iter_archive(archive) for archive in archives[\"train\"]],\n",
    "                    \"split\": \"train\",\n",
    "                },\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def _generate_examples(self, archives, split):\n",
    "        \"\"\"Yields examples.\"\"\"\n",
    "        idx = 0\n",
    "        for archive in archives:\n",
    "            for path, file in archive:\n",
    "                if path.endswith(\".png\"):\n",
    "                    name = path.split(\"/\")[-1].rsplit(\".\", 1)[0]\n",
    "                    ex = {\"image\": {\"path\": path, \"bytes\": file.read()}, \"name\": name}\n",
    "                    yield idx, ex\n",
    "                    idx += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"22\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.64001F\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">]\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "yt = YouTube('https://www.youtube.com/watch?v=7NNxK3CqaDk')\n",
    "stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "print(stream)\n",
    "stream.download()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
